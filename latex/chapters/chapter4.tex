%!TEX root = ../thesis.tex

\chapter{Implementation}
\label{ch:implementation}

This section outlines how I created my version of the COMER framework. It presents the overview of solution, the example of usage, some intricacies of implementation and some thoughts on possible improvements.

\section{Details of Implementation}\label{sec:details-of-implementation}

The implementation is encapsulated within a Python library, which can be seamlessly installed via the Python package manager, pip.
This library facilitates testing procedures by requiring input parameters, constraints, Metamorphic Relations and producing concrete test cases.
Library can be integrated with popular Python testing frameworks like \textit{Pytest}, \textit{unittest} or any major ones, given the simplicity of its usage.

Under the hood, implementation utilizes \textit{python-constraint} package \cite{python-constraint}, which is a Constraint Satisfaction Solver written in Python. The choice was dictated by popularity of the tool and a lot of useful features. It supports different kind of constraints, including user-defined. It is also capable of using Backtracking, Recursive Backtracking and Minimum conflicts solvers. For my implementation, I decided to stick with Backtracking solver because it allows iterative generation of multiple solutions without solving the whole problem.

For the t-way generation I decided to use AllPairs method of generating tests. It has great efficiency and is easy to implement and extend, which is great for my use case \cite{pairwise}. Nevertheless, other methods could be used instead of AllPairs. The requirements for the method are:
\begin{itemize}
	\item It should produce test cases which satisfy t-way coverage.
	\item It should be able to iteratively produce new test case given already existing ones.
	\item It should support specifying constraints in function form.
\end{itemize}

\subsection{Testing}\label{sec:testing}

For testing the tool efficiency I needed a way interact with web applications. I decided to use Web Testing framework called \textit{playwright} \cite{playwright} which allows automation of web browser interactions via code. This tool is widely adopted in industry and has an integration with Pytest and Python in general. I used it to execute test cases produced by my library. Below is an example of injecting SQL via web form using playwright:

\begin{lstlisting}[label={lst:playwright}]
def sql(self, query: str) -> str:
	self.page.goto("http://localhost:4280/vulnerabilities/sqli_blind/")
	self.page.get_by_role("textbox").fill(query)
	self.page.get_by_role("button", name="Submit").click()
	pre = self.page.locator("pre")
	if self.page.get_by_text("There was an error.").is_visible():
		return ""
	if pre.is_visible():
		return pre.inner_text()
	return ""
\end{lstlisting}

\subsection{COMER implementation}\label{sec:comer-implementation}

The main function responsible for generating test cases is as follows:

\begin{lstlisting}[label={lst:test-case1}]
def __next__(self) -> OrderedDict:
	r = random.random()
	if r > self._mr_probability and self.generated_cases:
		case_pre = random.choice(self.generated_cases)
		solution = self.csp_solver(case_pre)
		if solution:
			self.add_testcase_to_tested(solution)
			return solution

	return OrderedDict(super().__next__())

\end{lstlisting}

The function adheres to the foundational principles of the COMER framework.
Specifically, based on a given probability, \verb|self._mr_probability|, function chooses either a Combinatorial Testing (CT) or Metamorphic Testing (MT) based approach.
In CT, it uses a Constraint Satisfaction Problem (CSP) solver to generate test cases iteratively.
In MT, it selects an existing test case (\verb|case_pre|) from the provided pool (\verb|self.generated_cases|) and generates subsequent test cases using the CSP solver.

\section{Using framework}

The example demonstrates how to use the framework for testing a web application. Suppose we want to test a web application that allows users to add bookmarks and smart tags to their accounts. We can define a set of parameters for our test cases as follows:

\begin{lstlisting}[label={lst:test-case2}]
params = OrderedDict(
	{
		"highlight": [0, 1],
		"status_bar": [0, 1],
		"bookmarks": [0, 1],
		"smart_tags": [0, 1],
	}
)
\end{lstlisting}

Constraints are defined as a functions which accept test case as input and produce True or False indicating whether we should include particular test case into our domain. MRs are defined using test case as input and a new follow up as an output. In this particular example we do not define additional MR for generating concrete test cases for simplicity sake.

\begin{lstlisting}[label={lst:test-case3}]
def constraint(highlight, status_bar, **kwargs):
	return highlight == status_bar

def mr(bookmarks, smart_tags, **kwargs):
	return OrderedDict({
		"bookmarks": smart_tags,
		"smart_tags": bookmarks,
		**kwargs
	})
\end{lstlisting}

After our domain is set, we can produce abstract test cases. In this example we use them as input to \textit{Pytest} for producing parameterized test cases.

\begin{lstlisting}[label={lst:test-case4}]
@pytest.mark.parametrize("testcase", Comer(params, constraint, MR(mr)))
def test_simple(testcase: OrderedDict):
	assert testcase["highlight"] == testcase["status_bar"]
\end{lstlisting}
